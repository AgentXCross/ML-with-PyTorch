{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c12c5e2b",
   "metadata": {},
   "source": [
    "# Neural Network Rossmann Sales Prediction Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bb715ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_style('darkgrid')\n",
    "matplotlib.rcParams['font.size'] = 14\n",
    "matplotlib.rcParams['figure.figsize'] = (10, 6)\n",
    "matplotlib.rcParams['figure.facecolor'] = '#00000000'\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c72ac266",
   "metadata": {},
   "outputs": [],
   "source": [
    "ross_df = pd.read_csv('../Data/train.csv', low_memory = False)\n",
    "store_df = pd.read_csv('../Data/store.csv')\n",
    "test_df = pd.read_csv('../Data/test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcd1e1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_train_df = ross_df.merge(store_df, how = 'left', on = 'Store')\n",
    "merged_test_df = test_df.merge(store_df, how = 'left', on = 'Store')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "213220a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1017209 entries, 0 to 1017208\n",
      "Data columns (total 18 columns):\n",
      " #   Column                     Non-Null Count    Dtype  \n",
      "---  ------                     --------------    -----  \n",
      " 0   Store                      1017209 non-null  int64  \n",
      " 1   DayOfWeek                  1017209 non-null  int64  \n",
      " 2   Date                       1017209 non-null  object \n",
      " 3   Sales                      1017209 non-null  int64  \n",
      " 4   Customers                  1017209 non-null  int64  \n",
      " 5   Open                       1017209 non-null  int64  \n",
      " 6   Promo                      1017209 non-null  int64  \n",
      " 7   StateHoliday               1017209 non-null  object \n",
      " 8   SchoolHoliday              1017209 non-null  int64  \n",
      " 9   StoreType                  1017209 non-null  object \n",
      " 10  Assortment                 1017209 non-null  object \n",
      " 11  CompetitionDistance        1014567 non-null  float64\n",
      " 12  CompetitionOpenSinceMonth  693861 non-null   float64\n",
      " 13  CompetitionOpenSinceYear   693861 non-null   float64\n",
      " 14  Promo2                     1017209 non-null  int64  \n",
      " 15  Promo2SinceWeek            509178 non-null   float64\n",
      " 16  Promo2SinceYear            509178 non-null   float64\n",
      " 17  PromoInterval              509178 non-null   object \n",
      "dtypes: float64(5), int64(8), object(5)\n",
      "memory usage: 139.7+ MB\n"
     ]
    }
   ],
   "source": [
    "merged_train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11852b91",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2a9750",
   "metadata": {},
   "source": [
    "### Date Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27043d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_features(df):\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    df['DayOfMonth'] = df['Date'].dt.day\n",
    "    df['Month'] = df['Date'].dt.month\n",
    "    df['Year'] = df['Date'].dt.year\n",
    "    df['Quarter'] = df['Date'].dt.quarter\n",
    "    df['IsWeekend'] = df['DayOfWeek'].isin([6, 7]).astype(int)\n",
    "    df['WeekOfYear'] = df['Date'].dt.isocalendar().week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "444b0dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_features(merged_train_df)\n",
    "date_features(merged_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7de65eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove all rows where open = 0\n",
    "merged_train_df = merged_train_df.loc[merged_train_df['Open'] == 1].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3b7404",
   "metadata": {},
   "source": [
    "### How long has the competition been open in Months? (Feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7332149",
   "metadata": {},
   "outputs": [],
   "source": [
    "def competition_open_months(df):\n",
    "    df['CompetitionOpenMonths'] = 12 * (df['Year'] - df['CompetitionOpenSinceYear']) + (df['Month'] - df['CompetitionOpenSinceMonth'])\n",
    "    df['CompetitionOpenMonths'] = df['CompetitionOpenMonths'].map(lambda x: 0 if x < 0 else x).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce1e96d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "competition_open_months(merged_train_df)\n",
    "competition_open_months(merged_test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c8c87a",
   "metadata": {},
   "source": [
    "### Feature: How long has Promo2 been running and is it currently a Promo2 Month?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07e39176",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Date</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Customers</th>\n",
       "      <th>Open</th>\n",
       "      <th>Promo</th>\n",
       "      <th>StateHoliday</th>\n",
       "      <th>SchoolHoliday</th>\n",
       "      <th>StoreType</th>\n",
       "      <th>Assortment</th>\n",
       "      <th>CompetitionDistance</th>\n",
       "      <th>CompetitionOpenSinceMonth</th>\n",
       "      <th>CompetitionOpenSinceYear</th>\n",
       "      <th>Promo2</th>\n",
       "      <th>Promo2SinceWeek</th>\n",
       "      <th>Promo2SinceYear</th>\n",
       "      <th>PromoInterval</th>\n",
       "      <th>DayOfMonth</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>IsWeekend</th>\n",
       "      <th>WeekOfYear</th>\n",
       "      <th>CompetitionOpenMonths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>949558</th>\n",
       "      <td>364</td>\n",
       "      <td>6</td>\n",
       "      <td>2013-03-02</td>\n",
       "      <td>1750</td>\n",
       "      <td>266</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>13620.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>Mar,Jun,Sept,Dec</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993044</th>\n",
       "      <td>365</td>\n",
       "      <td>2</td>\n",
       "      <td>2013-01-22</td>\n",
       "      <td>6219</td>\n",
       "      <td>629</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>2410.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>45.0</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>Feb,May,Aug,Nov</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Store  DayOfWeek       Date  Sales  Customers  Open  Promo  \\\n",
       "949558    364          6 2013-03-02   1750        266     1      0   \n",
       "993044    365          2 2013-01-22   6219        629     1      1   \n",
       "\n",
       "       StateHoliday  SchoolHoliday StoreType Assortment  CompetitionDistance  \\\n",
       "949558            0              0         a          c              13620.0   \n",
       "993044            0              0         c          a               2410.0   \n",
       "\n",
       "        CompetitionOpenSinceMonth  CompetitionOpenSinceYear  Promo2  \\\n",
       "949558                        NaN                       NaN       1   \n",
       "993044                        NaN                       NaN       1   \n",
       "\n",
       "        Promo2SinceWeek  Promo2SinceYear     PromoInterval  DayOfMonth  Month  \\\n",
       "949558             10.0           2014.0  Mar,Jun,Sept,Dec           2      3   \n",
       "993044             45.0           2009.0   Feb,May,Aug,Nov          22      1   \n",
       "\n",
       "        Year  Quarter  IsWeekend  WeekOfYear  CompetitionOpenMonths  \n",
       "949558  2013        1          1           9                    0.0  \n",
       "993044  2013        1          0           4                    0.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_train_df.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "686e2110",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_promo_month(row):\n",
    "    month_to_string = {\n",
    "        1: 'Jan', 2: 'Feb', 3: 'Mar', 4: 'Apr', 5: 'May', 6: 'Jun',\n",
    "        7: 'Jul', 8: 'Aug', 9: 'Sept', 10: 'Oct', 11: 'Nov', 12: 'Dec'\n",
    "    }\n",
    "    try: \n",
    "        months = (row['PromoInterval'] or '').split(',')\n",
    "        if row['Promo2OpenMonths'] and month_to_string[row['Month']] in months:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    except Exception:\n",
    "        return 0\n",
    "    \n",
    "def promo_columns(df):\n",
    "    df['Promo2OpenMonths'] = 12 * (df['Year'] - df['Promo2SinceYear']) + (df['WeekOfYear'] - df['Promo2SinceWeek']) * 7/30.5\n",
    "    df['Promo2OpenMonths'] = df['Promo2OpenMonths'].map(lambda x: 0 if x < 0 else x).fillna(0) * df['Promo2']\n",
    "    df['IsPromo2Month'] = df.apply(check_promo_month, axis = 1) * df['Promo2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6086e4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "promo_columns(merged_train_df)\n",
    "promo_columns(merged_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04c059d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 844392 entries, 0 to 1017190\n",
      "Data columns (total 27 columns):\n",
      " #   Column                     Non-Null Count   Dtype         \n",
      "---  ------                     --------------   -----         \n",
      " 0   Store                      844392 non-null  int64         \n",
      " 1   DayOfWeek                  844392 non-null  int64         \n",
      " 2   Date                       844392 non-null  datetime64[ns]\n",
      " 3   Sales                      844392 non-null  int64         \n",
      " 4   Customers                  844392 non-null  int64         \n",
      " 5   Open                       844392 non-null  int64         \n",
      " 6   Promo                      844392 non-null  int64         \n",
      " 7   StateHoliday               844392 non-null  object        \n",
      " 8   SchoolHoliday              844392 non-null  int64         \n",
      " 9   StoreType                  844392 non-null  object        \n",
      " 10  Assortment                 844392 non-null  object        \n",
      " 11  CompetitionDistance        842206 non-null  float64       \n",
      " 12  CompetitionOpenSinceMonth  575773 non-null  float64       \n",
      " 13  CompetitionOpenSinceYear   575773 non-null  float64       \n",
      " 14  Promo2                     844392 non-null  int64         \n",
      " 15  Promo2SinceWeek            421085 non-null  float64       \n",
      " 16  Promo2SinceYear            421085 non-null  float64       \n",
      " 17  PromoInterval              421085 non-null  object        \n",
      " 18  DayOfMonth                 844392 non-null  int32         \n",
      " 19  Month                      844392 non-null  int32         \n",
      " 20  Year                       844392 non-null  int32         \n",
      " 21  Quarter                    844392 non-null  int32         \n",
      " 22  IsWeekend                  844392 non-null  int64         \n",
      " 23  WeekOfYear                 844392 non-null  UInt32        \n",
      " 24  CompetitionOpenMonths      844392 non-null  float64       \n",
      " 25  Promo2OpenMonths           844392 non-null  float64       \n",
      " 26  IsPromo2Month              844392 non-null  int64         \n",
      "dtypes: UInt32(1), datetime64[ns](1), float64(7), int32(4), int64(10), object(4)\n",
      "memory usage: 165.1+ MB\n"
     ]
    }
   ],
   "source": [
    "merged_train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6623ab12",
   "metadata": {},
   "source": [
    "### Store Level Aggregations (Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3de49994",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_agg = merged_train_df.groupby('Store').agg(\n",
    "    Store_Avg_Sales = ('Sales', 'mean'),\n",
    "    Store_Median_Sales = ('Sales', 'median'),\n",
    "    Store_Std_Sales = ('Sales', 'std'),\n",
    "    Store_Max_Sales = ('Sales', 'max'),\n",
    "    Store_Min_Sales = ('Sales', 'min')\n",
    ").reset_index()\n",
    "#In case only 1 data point for a store\n",
    "store_agg['Store_Std_Sales'] = store_agg['Store_Std_Sales'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ae65609",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_train_df = merged_train_df.merge(store_agg, how = 'left', on = 'Store')\n",
    "merged_test_df = merged_test_df.merge(store_agg, how = 'left', on = 'Store')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1a178a",
   "metadata": {},
   "source": [
    "## Imputation: Competition Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2cb7acc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(75860.0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Impute nan's in competition distance with 100,000km\n",
    "merged_train_df['CompetitionDistance'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "64c19214",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_train_df['CompetitionDistance'] = merged_train_df['CompetitionDistance'].fillna(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "615db362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 844392 entries, 0 to 844391\n",
      "Data columns (total 32 columns):\n",
      " #   Column                     Non-Null Count   Dtype         \n",
      "---  ------                     --------------   -----         \n",
      " 0   Store                      844392 non-null  int64         \n",
      " 1   DayOfWeek                  844392 non-null  int64         \n",
      " 2   Date                       844392 non-null  datetime64[ns]\n",
      " 3   Sales                      844392 non-null  int64         \n",
      " 4   Customers                  844392 non-null  int64         \n",
      " 5   Open                       844392 non-null  int64         \n",
      " 6   Promo                      844392 non-null  int64         \n",
      " 7   StateHoliday               844392 non-null  object        \n",
      " 8   SchoolHoliday              844392 non-null  int64         \n",
      " 9   StoreType                  844392 non-null  object        \n",
      " 10  Assortment                 844392 non-null  object        \n",
      " 11  CompetitionDistance        844392 non-null  float64       \n",
      " 12  CompetitionOpenSinceMonth  575773 non-null  float64       \n",
      " 13  CompetitionOpenSinceYear   575773 non-null  float64       \n",
      " 14  Promo2                     844392 non-null  int64         \n",
      " 15  Promo2SinceWeek            421085 non-null  float64       \n",
      " 16  Promo2SinceYear            421085 non-null  float64       \n",
      " 17  PromoInterval              421085 non-null  object        \n",
      " 18  DayOfMonth                 844392 non-null  int32         \n",
      " 19  Month                      844392 non-null  int32         \n",
      " 20  Year                       844392 non-null  int32         \n",
      " 21  Quarter                    844392 non-null  int32         \n",
      " 22  IsWeekend                  844392 non-null  int64         \n",
      " 23  WeekOfYear                 844392 non-null  UInt32        \n",
      " 24  CompetitionOpenMonths      844392 non-null  float64       \n",
      " 25  Promo2OpenMonths           844392 non-null  float64       \n",
      " 26  IsPromo2Month              844392 non-null  int64         \n",
      " 27  Store_Avg_Sales            844392 non-null  float64       \n",
      " 28  Store_Median_Sales         844392 non-null  float64       \n",
      " 29  Store_Std_Sales            844392 non-null  float64       \n",
      " 30  Store_Max_Sales            844392 non-null  int64         \n",
      " 31  Store_Min_Sales            844392 non-null  int64         \n",
      "dtypes: UInt32(1), datetime64[ns](1), float64(10), int32(4), int64(12), object(4)\n",
      "memory usage: 190.9+ MB\n"
     ]
    }
   ],
   "source": [
    "merged_train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a24a665",
   "metadata": {},
   "source": [
    "## Input and Output Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "afc74bd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Store', 'DayOfWeek', 'Date', 'Sales', 'Customers', 'Open', 'Promo',\n",
       "       'StateHoliday', 'SchoolHoliday', 'StoreType', 'Assortment',\n",
       "       'CompetitionDistance', 'CompetitionOpenSinceMonth',\n",
       "       'CompetitionOpenSinceYear', 'Promo2', 'Promo2SinceWeek',\n",
       "       'Promo2SinceYear', 'PromoInterval', 'DayOfMonth', 'Month', 'Year',\n",
       "       'Quarter', 'IsWeekend', 'WeekOfYear', 'CompetitionOpenMonths',\n",
       "       'Promo2OpenMonths', 'IsPromo2Month', 'Store_Avg_Sales',\n",
       "       'Store_Median_Sales', 'Store_Std_Sales', 'Store_Max_Sales',\n",
       "       'Store_Min_Sales'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5f87e0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_columns = [\n",
    "    'DayOfWeek', 'Promo', 'StateHoliday', 'SchoolHoliday', \n",
    "    'StoreType', 'Assortment','CompetitionDistance',\n",
    "    'Promo2', 'DayOfMonth', 'Month', 'Year',\n",
    "    'Quarter', 'IsWeekend', 'WeekOfYear', 'CompetitionOpenMonths',\n",
    "    'Promo2OpenMonths', 'IsPromo2Month', 'Store_Avg_Sales',\n",
    "    'Store_Median_Sales', 'Store_Std_Sales', 'Store_Max_Sales',\n",
    "    'Store_Min_Sales'\n",
    "]\n",
    "\n",
    "output_column = ['Sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7dc94d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_non_adjusted = merged_train_df[input_columns].copy()\n",
    "y_train_non_adjusted = merged_train_df[output_column].copy()\n",
    "\n",
    "X_test_non_adjusted = merged_test_df[input_columns].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7a8e51ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = [\n",
    "    'Promo', 'SchoolHoliday', 'CompetitionDistance', 'Promo2',\n",
    "    'Year', 'IsWeekend', 'CompetitionOpenMonths', 'Promo2OpenMonths',\n",
    "    'IsPromo2Month', 'Store_Avg_Sales',\n",
    "    'Store_Median_Sales', 'Store_Std_Sales', 'Store_Max_Sales',\n",
    "    'Store_Min_Sales'\n",
    "]\n",
    "categorical_columns = [\n",
    "    'DayOfWeek', 'DayOfMonth', 'StateHoliday', 'StoreType', \n",
    "    'Assortment', 'Month', 'Quarter', 'WeekOfYear'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307a95ff",
   "metadata": {},
   "source": [
    "## Scalling Numeric Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "269e87ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler().fit(X_train_non_adjusted[numeric_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8d8fcb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_non_adjusted[numeric_columns] = scaler.transform(X_train_non_adjusted[numeric_columns])\n",
    "X_test_non_adjusted[numeric_columns] = scaler.transform(X_test_non_adjusted[numeric_columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5747426",
   "metadata": {},
   "source": [
    "## OneHot Encoding Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6f76a66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse_output = False, handle_unknown = 'ignore').fit(X_train_non_adjusted[categorical_columns])\n",
    "encoded_columns = list(encoder.get_feature_names_out(categorical_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fc40772b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1p/bkw8vf0537qgpg1zgyfwq80r0000gn/T/ipykernel_92548/1875367073.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_non_adjusted[encoded_columns] = encoder.transform(X_train_non_adjusted[categorical_columns])\n",
      "/var/folders/1p/bkw8vf0537qgpg1zgyfwq80r0000gn/T/ipykernel_92548/1875367073.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_non_adjusted[encoded_columns] = encoder.transform(X_train_non_adjusted[categorical_columns])\n",
      "/var/folders/1p/bkw8vf0537qgpg1zgyfwq80r0000gn/T/ipykernel_92548/1875367073.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_non_adjusted[encoded_columns] = encoder.transform(X_train_non_adjusted[categorical_columns])\n",
      "/var/folders/1p/bkw8vf0537qgpg1zgyfwq80r0000gn/T/ipykernel_92548/1875367073.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_non_adjusted[encoded_columns] = encoder.transform(X_train_non_adjusted[categorical_columns])\n",
      "/var/folders/1p/bkw8vf0537qgpg1zgyfwq80r0000gn/T/ipykernel_92548/1875367073.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_non_adjusted[encoded_columns] = encoder.transform(X_train_non_adjusted[categorical_columns])\n",
      "/var/folders/1p/bkw8vf0537qgpg1zgyfwq80r0000gn/T/ipykernel_92548/1875367073.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_non_adjusted[encoded_columns] = encoder.transform(X_train_non_adjusted[categorical_columns])\n",
      "/var/folders/1p/bkw8vf0537qgpg1zgyfwq80r0000gn/T/ipykernel_92548/1875367073.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_non_adjusted[encoded_columns] = encoder.transform(X_train_non_adjusted[categorical_columns])\n",
      "/var/folders/1p/bkw8vf0537qgpg1zgyfwq80r0000gn/T/ipykernel_92548/1875367073.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_non_adjusted[encoded_columns] = encoder.transform(X_train_non_adjusted[categorical_columns])\n",
      "/var/folders/1p/bkw8vf0537qgpg1zgyfwq80r0000gn/T/ipykernel_92548/1875367073.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_non_adjusted[encoded_columns] = encoder.transform(X_train_non_adjusted[categorical_columns])\n",
      "/var/folders/1p/bkw8vf0537qgpg1zgyfwq80r0000gn/T/ipykernel_92548/1875367073.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_non_adjusted[encoded_columns] = encoder.transform(X_train_non_adjusted[categorical_columns])\n",
      "/var/folders/1p/bkw8vf0537qgpg1zgyfwq80r0000gn/T/ipykernel_92548/1875367073.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_non_adjusted[encoded_columns] = encoder.transform(X_train_non_adjusted[categorical_columns])\n",
      "/var/folders/1p/bkw8vf0537qgpg1zgyfwq80r0000gn/T/ipykernel_92548/1875367073.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_non_adjusted[encoded_columns] = encoder.transform(X_train_non_adjusted[categorical_columns])\n",
      "/var/folders/1p/bkw8vf0537qgpg1zgyfwq80r0000gn/T/ipykernel_92548/1875367073.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_non_adjusted[encoded_columns] = encoder.transform(X_train_non_adjusted[categorical_columns])\n",
      "/var/folders/1p/bkw8vf0537qgpg1zgyfwq80r0000gn/T/ipykernel_92548/1875367073.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_non_adjusted[encoded_columns] = encoder.transform(X_train_non_adjusted[categorical_columns])\n",
      "/var/folders/1p/bkw8vf0537qgpg1zgyfwq80r0000gn/T/ipykernel_92548/1875367073.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_non_adjusted[encoded_columns] = encoder.transform(X_train_non_adjusted[categorical_columns])\n",
      "/var/folders/1p/bkw8vf0537qgpg1zgyfwq80r0000gn/T/ipykernel_92548/1875367073.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_non_adjusted[encoded_columns] = encoder.transform(X_train_non_adjusted[categorical_columns])\n",
      "/var/folders/1p/bkw8vf0537qgpg1zgyfwq80r0000gn/T/ipykernel_92548/1875367073.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_non_adjusted[encoded_columns] = encoder.transform(X_train_non_adjusted[categorical_columns])\n",
      "/var/folders/1p/bkw8vf0537qgpg1zgyfwq80r0000gn/T/ipykernel_92548/1875367073.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_non_adjusted[encoded_columns] = encoder.transform(X_train_non_adjusted[categorical_columns])\n",
      "/var/folders/1p/bkw8vf0537qgpg1zgyfwq80r0000gn/T/ipykernel_92548/1875367073.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_non_adjusted[encoded_columns] = encoder.transform(X_train_non_adjusted[categorical_columns])\n",
      "/var/folders/1p/bkw8vf0537qgpg1zgyfwq80r0000gn/T/ipykernel_92548/1875367073.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_non_adjusted[encoded_columns] = encoder.transform(X_train_non_adjusted[categorical_columns])\n",
      "/var/folders/1p/bkw8vf0537qgpg1zgyfwq80r0000gn/T/ipykernel_92548/1875367073.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_non_adjusted[encoded_columns] = encoder.transform(X_train_non_adjusted[categorical_columns])\n",
      "/var/folders/1p/bkw8vf0537qgpg1zgyfwq80r0000gn/T/ipykernel_92548/1875367073.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_non_adjusted[encoded_columns] = encoder.transform(X_train_non_adjusted[categorical_columns])\n",
      "/var/folders/1p/bkw8vf0537qgpg1zgyfwq80r0000gn/T/ipykernel_92548/1875367073.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_non_adjusted[encoded_columns] = encoder.transform(X_train_non_adjusted[categorical_columns])\n",
      "/var/folders/1p/bkw8vf0537qgpg1zgyfwq80r0000gn/T/ipykernel_92548/1875367073.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_non_adjusted[encoded_columns] = encoder.transform(X_train_non_adjusted[categorical_columns])\n",
      "/var/folders/1p/bkw8vf0537qgpg1zgyfwq80r0000gn/T/ipykernel_92548/1875367073.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_non_adjusted[encoded_columns] = encoder.transform(X_train_non_adjusted[categorical_columns])\n",
      "/var/folders/1p/bkw8vf0537qgpg1zgyfwq80r0000gn/T/ipykernel_92548/1875367073.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_non_adjusted[encoded_columns] = encoder.transform(X_train_non_adjusted[categorical_columns])\n",
      "/var/folders/1p/bkw8vf0537qgpg1zgyfwq80r0000gn/T/ipykernel_92548/1875367073.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_non_adjusted[encoded_columns] = encoder.transform(X_train_non_adjusted[categorical_columns])\n",
      "/var/folders/1p/bkw8vf0537qgpg1zgyfwq80r0000gn/T/ipykernel_92548/1875367073.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_non_adjusted[encoded_columns] = encoder.transform(X_train_non_adjusted[categorical_columns])\n",
      "/var/folders/1p/bkw8vf0537qgpg1zgyfwq80r0000gn/T/ipykernel_92548/1875367073.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_non_adjusted[encoded_columns] = encoder.transform(X_train_non_adjusted[categorical_columns])\n",
      "/var/folders/1p/bkw8vf0537qgpg1zgyfwq80r0000gn/T/ipykernel_92548/1875367073.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_non_adjusted[encoded_columns] = encoder.transform(X_train_non_adjusted[categorical_columns])\n",
      "/var/folders/1p/bkw8vf0537qgpg1zgyfwq80r0000gn/T/ipykernel_92548/1875367073.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_non_adjusted[encoded_columns] = encoder.transform(X_train_non_adjusted[categorical_columns])\n",
      "/var/folders/1p/bkw8vf0537qgpg1zgyfwq80r0000gn/T/ipykernel_92548/1875367073.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_non_adjusted[encoded_columns] = encoder.transform(X_train_non_adjusted[categorical_columns])\n",
      "/var/folders/1p/bkw8vf0537qgpg1zgyfwq80r0000gn/T/ipykernel_92548/1875367073.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_non_adjusted[encoded_columns] = encoder.transform(X_train_non_adjusted[categorical_columns])\n",
      "/var/folders/1p/bkw8vf0537qgpg1zgyfwq80r0000gn/T/ipykernel_92548/1875367073.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_non_adjusted[encoded_columns] = encoder.transform(X_train_non_adjusted[categorical_columns])\n",
      "/var/folders/1p/bkw8vf0537qgpg1zgyfwq80r0000gn/T/ipykernel_92548/1875367073.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_non_adjusted[encoded_columns] = encoder.transform(X_train_non_adjusted[categorical_columns])\n",
      "/var/folders/1p/bkw8vf0537qgpg1zgyfwq80r0000gn/T/ipykernel_92548/1875367073.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_non_adjusted[encoded_columns] = encoder.transform(X_test_non_adjusted[categorical_columns])\n",
      "/var/folders/1p/bkw8vf0537qgpg1zgyfwq80r0000gn/T/ipykernel_92548/1875367073.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_non_adjusted[encoded_columns] = encoder.transform(X_test_non_adjusted[categorical_columns])\n",
      "/var/folders/1p/bkw8vf0537qgpg1zgyfwq80r0000gn/T/ipykernel_92548/1875367073.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_non_adjusted[encoded_columns] = encoder.transform(X_test_non_adjusted[categorical_columns])\n",
      "/var/folders/1p/bkw8vf0537qgpg1zgyfwq80r0000gn/T/ipykernel_92548/1875367073.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_non_adjusted[encoded_columns] = encoder.transform(X_test_non_adjusted[categorical_columns])\n",
      "/var/folders/1p/bkw8vf0537qgpg1zgyfwq80r0000gn/T/ipykernel_92548/1875367073.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_non_adjusted[encoded_columns] = encoder.transform(X_test_non_adjusted[categorical_columns])\n",
      "/var/folders/1p/bkw8vf0537qgpg1zgyfwq80r0000gn/T/ipykernel_92548/1875367073.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_non_adjusted[encoded_columns] = encoder.transform(X_test_non_adjusted[categorical_columns])\n",
      "/var/folders/1p/bkw8vf0537qgpg1zgyfwq80r0000gn/T/ipykernel_92548/1875367073.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_non_adjusted[encoded_columns] = encoder.transform(X_test_non_adjusted[categorical_columns])\n",
      "/var/folders/1p/bkw8vf0537qgpg1zgyfwq80r0000gn/T/ipykernel_92548/1875367073.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_non_adjusted[encoded_columns] = encoder.transform(X_test_non_adjusted[categorical_columns])\n",
      "/var/folders/1p/bkw8vf0537qgpg1zgyfwq80r0000gn/T/ipykernel_92548/1875367073.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_non_adjusted[encoded_columns] = encoder.transform(X_test_non_adjusted[categorical_columns])\n",
      "/var/folders/1p/bkw8vf0537qgpg1zgyfwq80r0000gn/T/ipykernel_92548/1875367073.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_non_adjusted[encoded_columns] = encoder.transform(X_test_non_adjusted[categorical_columns])\n",
      "/var/folders/1p/bkw8vf0537qgpg1zgyfwq80r0000gn/T/ipykernel_92548/1875367073.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_non_adjusted[encoded_columns] = encoder.transform(X_test_non_adjusted[categorical_columns])\n",
      "/var/folders/1p/bkw8vf0537qgpg1zgyfwq80r0000gn/T/ipykernel_92548/1875367073.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_non_adjusted[encoded_columns] = encoder.transform(X_test_non_adjusted[categorical_columns])\n",
      "/var/folders/1p/bkw8vf0537qgpg1zgyfwq80r0000gn/T/ipykernel_92548/1875367073.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_non_adjusted[encoded_columns] = encoder.transform(X_test_non_adjusted[categorical_columns])\n",
      "/var/folders/1p/bkw8vf0537qgpg1zgyfwq80r0000gn/T/ipykernel_92548/1875367073.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_non_adjusted[encoded_columns] = encoder.transform(X_test_non_adjusted[categorical_columns])\n",
      "/var/folders/1p/bkw8vf0537qgpg1zgyfwq80r0000gn/T/ipykernel_92548/1875367073.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_non_adjusted[encoded_columns] = encoder.transform(X_test_non_adjusted[categorical_columns])\n",
      "/var/folders/1p/bkw8vf0537qgpg1zgyfwq80r0000gn/T/ipykernel_92548/1875367073.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_non_adjusted[encoded_columns] = encoder.transform(X_test_non_adjusted[categorical_columns])\n",
      "/var/folders/1p/bkw8vf0537qgpg1zgyfwq80r0000gn/T/ipykernel_92548/1875367073.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_non_adjusted[encoded_columns] = encoder.transform(X_test_non_adjusted[categorical_columns])\n",
      "/var/folders/1p/bkw8vf0537qgpg1zgyfwq80r0000gn/T/ipykernel_92548/1875367073.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_non_adjusted[encoded_columns] = encoder.transform(X_test_non_adjusted[categorical_columns])\n",
      "/var/folders/1p/bkw8vf0537qgpg1zgyfwq80r0000gn/T/ipykernel_92548/1875367073.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_non_adjusted[encoded_columns] = encoder.transform(X_test_non_adjusted[categorical_columns])\n",
      "/var/folders/1p/bkw8vf0537qgpg1zgyfwq80r0000gn/T/ipykernel_92548/1875367073.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_non_adjusted[encoded_columns] = encoder.transform(X_test_non_adjusted[categorical_columns])\n",
      "/var/folders/1p/bkw8vf0537qgpg1zgyfwq80r0000gn/T/ipykernel_92548/1875367073.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_non_adjusted[encoded_columns] = encoder.transform(X_test_non_adjusted[categorical_columns])\n",
      "/var/folders/1p/bkw8vf0537qgpg1zgyfwq80r0000gn/T/ipykernel_92548/1875367073.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_non_adjusted[encoded_columns] = encoder.transform(X_test_non_adjusted[categorical_columns])\n",
      "/var/folders/1p/bkw8vf0537qgpg1zgyfwq80r0000gn/T/ipykernel_92548/1875367073.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_non_adjusted[encoded_columns] = encoder.transform(X_test_non_adjusted[categorical_columns])\n",
      "/var/folders/1p/bkw8vf0537qgpg1zgyfwq80r0000gn/T/ipykernel_92548/1875367073.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_non_adjusted[encoded_columns] = encoder.transform(X_test_non_adjusted[categorical_columns])\n",
      "/var/folders/1p/bkw8vf0537qgpg1zgyfwq80r0000gn/T/ipykernel_92548/1875367073.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_non_adjusted[encoded_columns] = encoder.transform(X_test_non_adjusted[categorical_columns])\n",
      "/var/folders/1p/bkw8vf0537qgpg1zgyfwq80r0000gn/T/ipykernel_92548/1875367073.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_non_adjusted[encoded_columns] = encoder.transform(X_test_non_adjusted[categorical_columns])\n",
      "/var/folders/1p/bkw8vf0537qgpg1zgyfwq80r0000gn/T/ipykernel_92548/1875367073.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_non_adjusted[encoded_columns] = encoder.transform(X_test_non_adjusted[categorical_columns])\n",
      "/var/folders/1p/bkw8vf0537qgpg1zgyfwq80r0000gn/T/ipykernel_92548/1875367073.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_non_adjusted[encoded_columns] = encoder.transform(X_test_non_adjusted[categorical_columns])\n",
      "/var/folders/1p/bkw8vf0537qgpg1zgyfwq80r0000gn/T/ipykernel_92548/1875367073.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_non_adjusted[encoded_columns] = encoder.transform(X_test_non_adjusted[categorical_columns])\n",
      "/var/folders/1p/bkw8vf0537qgpg1zgyfwq80r0000gn/T/ipykernel_92548/1875367073.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_non_adjusted[encoded_columns] = encoder.transform(X_test_non_adjusted[categorical_columns])\n",
      "/var/folders/1p/bkw8vf0537qgpg1zgyfwq80r0000gn/T/ipykernel_92548/1875367073.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_non_adjusted[encoded_columns] = encoder.transform(X_test_non_adjusted[categorical_columns])\n",
      "/var/folders/1p/bkw8vf0537qgpg1zgyfwq80r0000gn/T/ipykernel_92548/1875367073.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_non_adjusted[encoded_columns] = encoder.transform(X_test_non_adjusted[categorical_columns])\n",
      "/var/folders/1p/bkw8vf0537qgpg1zgyfwq80r0000gn/T/ipykernel_92548/1875367073.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_non_adjusted[encoded_columns] = encoder.transform(X_test_non_adjusted[categorical_columns])\n",
      "/var/folders/1p/bkw8vf0537qgpg1zgyfwq80r0000gn/T/ipykernel_92548/1875367073.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_non_adjusted[encoded_columns] = encoder.transform(X_test_non_adjusted[categorical_columns])\n",
      "/var/folders/1p/bkw8vf0537qgpg1zgyfwq80r0000gn/T/ipykernel_92548/1875367073.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_non_adjusted[encoded_columns] = encoder.transform(X_test_non_adjusted[categorical_columns])\n"
     ]
    }
   ],
   "source": [
    "X_train_non_adjusted[encoded_columns] = encoder.transform(X_train_non_adjusted[categorical_columns])\n",
    "X_test_non_adjusted[encoded_columns] = encoder.transform(X_test_non_adjusted[categorical_columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771ac9ab",
   "metadata": {},
   "source": [
    "## Extract Final Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a78f3c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_non_adjusted[numeric_columns + encoded_columns].copy()\n",
    "y_train = y_train_non_adjusted.copy()\n",
    "\n",
    "X_test = X_test_non_adjusted[numeric_columns + encoded_columns].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fc506e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.sample(100).to_csv('../Data/input.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "72486785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Promo</th>\n",
       "      <th>SchoolHoliday</th>\n",
       "      <th>CompetitionDistance</th>\n",
       "      <th>Promo2</th>\n",
       "      <th>Year</th>\n",
       "      <th>IsWeekend</th>\n",
       "      <th>CompetitionOpenMonths</th>\n",
       "      <th>Promo2OpenMonths</th>\n",
       "      <th>IsPromo2Month</th>\n",
       "      <th>Store_Avg_Sales</th>\n",
       "      <th>Store_Median_Sales</th>\n",
       "      <th>Store_Std_Sales</th>\n",
       "      <th>Store_Max_Sales</th>\n",
       "      <th>Store_Min_Sales</th>\n",
       "      <th>DayOfWeek_1</th>\n",
       "      <th>DayOfWeek_2</th>\n",
       "      <th>DayOfWeek_3</th>\n",
       "      <th>DayOfWeek_4</th>\n",
       "      <th>DayOfWeek_5</th>\n",
       "      <th>DayOfWeek_6</th>\n",
       "      <th>DayOfWeek_7</th>\n",
       "      <th>DayOfMonth_1</th>\n",
       "      <th>DayOfMonth_2</th>\n",
       "      <th>DayOfMonth_3</th>\n",
       "      <th>DayOfMonth_4</th>\n",
       "      <th>DayOfMonth_5</th>\n",
       "      <th>DayOfMonth_6</th>\n",
       "      <th>DayOfMonth_7</th>\n",
       "      <th>DayOfMonth_8</th>\n",
       "      <th>DayOfMonth_9</th>\n",
       "      <th>DayOfMonth_10</th>\n",
       "      <th>DayOfMonth_11</th>\n",
       "      <th>DayOfMonth_12</th>\n",
       "      <th>DayOfMonth_13</th>\n",
       "      <th>DayOfMonth_14</th>\n",
       "      <th>DayOfMonth_15</th>\n",
       "      <th>DayOfMonth_16</th>\n",
       "      <th>DayOfMonth_17</th>\n",
       "      <th>DayOfMonth_18</th>\n",
       "      <th>DayOfMonth_19</th>\n",
       "      <th>DayOfMonth_20</th>\n",
       "      <th>DayOfMonth_21</th>\n",
       "      <th>DayOfMonth_22</th>\n",
       "      <th>DayOfMonth_23</th>\n",
       "      <th>DayOfMonth_24</th>\n",
       "      <th>DayOfMonth_25</th>\n",
       "      <th>DayOfMonth_26</th>\n",
       "      <th>DayOfMonth_27</th>\n",
       "      <th>DayOfMonth_28</th>\n",
       "      <th>DayOfMonth_29</th>\n",
       "      <th>DayOfMonth_30</th>\n",
       "      <th>DayOfMonth_31</th>\n",
       "      <th>StateHoliday_0</th>\n",
       "      <th>StateHoliday_a</th>\n",
       "      <th>StateHoliday_b</th>\n",
       "      <th>StateHoliday_c</th>\n",
       "      <th>StoreType_a</th>\n",
       "      <th>StoreType_b</th>\n",
       "      <th>StoreType_c</th>\n",
       "      <th>StoreType_d</th>\n",
       "      <th>Assortment_a</th>\n",
       "      <th>Assortment_b</th>\n",
       "      <th>Assortment_c</th>\n",
       "      <th>Month_1</th>\n",
       "      <th>Month_2</th>\n",
       "      <th>Month_3</th>\n",
       "      <th>Month_4</th>\n",
       "      <th>Month_5</th>\n",
       "      <th>Month_6</th>\n",
       "      <th>Month_7</th>\n",
       "      <th>Month_8</th>\n",
       "      <th>Month_9</th>\n",
       "      <th>Month_10</th>\n",
       "      <th>Month_11</th>\n",
       "      <th>Month_12</th>\n",
       "      <th>Quarter_1</th>\n",
       "      <th>Quarter_2</th>\n",
       "      <th>Quarter_3</th>\n",
       "      <th>Quarter_4</th>\n",
       "      <th>WeekOfYear_1.0</th>\n",
       "      <th>WeekOfYear_2.0</th>\n",
       "      <th>WeekOfYear_3.0</th>\n",
       "      <th>WeekOfYear_4.0</th>\n",
       "      <th>WeekOfYear_5.0</th>\n",
       "      <th>WeekOfYear_6.0</th>\n",
       "      <th>WeekOfYear_7.0</th>\n",
       "      <th>WeekOfYear_8.0</th>\n",
       "      <th>WeekOfYear_9.0</th>\n",
       "      <th>WeekOfYear_10.0</th>\n",
       "      <th>WeekOfYear_11.0</th>\n",
       "      <th>WeekOfYear_12.0</th>\n",
       "      <th>WeekOfYear_13.0</th>\n",
       "      <th>WeekOfYear_14.0</th>\n",
       "      <th>WeekOfYear_15.0</th>\n",
       "      <th>WeekOfYear_16.0</th>\n",
       "      <th>WeekOfYear_17.0</th>\n",
       "      <th>WeekOfYear_18.0</th>\n",
       "      <th>WeekOfYear_19.0</th>\n",
       "      <th>WeekOfYear_20.0</th>\n",
       "      <th>WeekOfYear_21.0</th>\n",
       "      <th>WeekOfYear_22.0</th>\n",
       "      <th>WeekOfYear_23.0</th>\n",
       "      <th>WeekOfYear_24.0</th>\n",
       "      <th>WeekOfYear_25.0</th>\n",
       "      <th>WeekOfYear_26.0</th>\n",
       "      <th>WeekOfYear_27.0</th>\n",
       "      <th>WeekOfYear_28.0</th>\n",
       "      <th>WeekOfYear_29.0</th>\n",
       "      <th>WeekOfYear_30.0</th>\n",
       "      <th>WeekOfYear_31.0</th>\n",
       "      <th>WeekOfYear_32.0</th>\n",
       "      <th>WeekOfYear_33.0</th>\n",
       "      <th>WeekOfYear_34.0</th>\n",
       "      <th>WeekOfYear_35.0</th>\n",
       "      <th>WeekOfYear_36.0</th>\n",
       "      <th>WeekOfYear_37.0</th>\n",
       "      <th>WeekOfYear_38.0</th>\n",
       "      <th>WeekOfYear_39.0</th>\n",
       "      <th>WeekOfYear_40.0</th>\n",
       "      <th>WeekOfYear_41.0</th>\n",
       "      <th>WeekOfYear_42.0</th>\n",
       "      <th>WeekOfYear_43.0</th>\n",
       "      <th>WeekOfYear_44.0</th>\n",
       "      <th>WeekOfYear_45.0</th>\n",
       "      <th>WeekOfYear_46.0</th>\n",
       "      <th>WeekOfYear_47.0</th>\n",
       "      <th>WeekOfYear_48.0</th>\n",
       "      <th>WeekOfYear_49.0</th>\n",
       "      <th>WeekOfYear_50.0</th>\n",
       "      <th>WeekOfYear_51.0</th>\n",
       "      <th>WeekOfYear_52.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.113726</td>\n",
       "      <td>2.041038</td>\n",
       "      <td>-0.483913</td>\n",
       "      <td>-0.997372</td>\n",
       "      <td>1.502796</td>\n",
       "      <td>-0.460344</td>\n",
       "      <td>0.614306</td>\n",
       "      <td>-0.686969</td>\n",
       "      <td>-0.418274</td>\n",
       "      <td>-0.912031</td>\n",
       "      <td>-0.875946</td>\n",
       "      <td>-1.347031</td>\n",
       "      <td>-1.099009</td>\n",
       "      <td>-0.281003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.113726</td>\n",
       "      <td>2.041038</td>\n",
       "      <td>-0.560331</td>\n",
       "      <td>1.002635</td>\n",
       "      <td>1.502796</td>\n",
       "      <td>-0.460344</td>\n",
       "      <td>0.767705</td>\n",
       "      <td>2.690605</td>\n",
       "      <td>2.390776</td>\n",
       "      <td>-0.831141</td>\n",
       "      <td>-0.817777</td>\n",
       "      <td>-0.393441</td>\n",
       "      <td>-0.883690</td>\n",
       "      <td>-0.571867</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.113726</td>\n",
       "      <td>2.041038</td>\n",
       "      <td>0.919988</td>\n",
       "      <td>1.002635</td>\n",
       "      <td>1.502796</td>\n",
       "      <td>-0.460344</td>\n",
       "      <td>0.936443</td>\n",
       "      <td>2.046518</td>\n",
       "      <td>2.390776</td>\n",
       "      <td>-0.005375</td>\n",
       "      <td>-0.032493</td>\n",
       "      <td>0.536538</td>\n",
       "      <td>0.050540</td>\n",
       "      <td>0.095873</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.113726</td>\n",
       "      <td>2.041038</td>\n",
       "      <td>-0.554872</td>\n",
       "      <td>-0.997372</td>\n",
       "      <td>1.502796</td>\n",
       "      <td>-0.460344</td>\n",
       "      <td>0.430228</td>\n",
       "      <td>-0.686969</td>\n",
       "      <td>-0.418274</td>\n",
       "      <td>1.114030</td>\n",
       "      <td>1.170027</td>\n",
       "      <td>0.126185</td>\n",
       "      <td>0.372025</td>\n",
       "      <td>2.021615</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.113726</td>\n",
       "      <td>2.041038</td>\n",
       "      <td>2.642660</td>\n",
       "      <td>-0.997372</td>\n",
       "      <td>1.502796</td>\n",
       "      <td>-0.460344</td>\n",
       "      <td>-0.597541</td>\n",
       "      <td>-0.686969</td>\n",
       "      <td>-0.418274</td>\n",
       "      <td>-0.946421</td>\n",
       "      <td>-0.889205</td>\n",
       "      <td>-0.145339</td>\n",
       "      <td>-0.695239</td>\n",
       "      <td>-0.897529</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Promo  SchoolHoliday  CompetitionDistance    Promo2      Year  \\\n",
       "0  1.113726       2.041038            -0.483913 -0.997372  1.502796   \n",
       "1  1.113726       2.041038            -0.560331  1.002635  1.502796   \n",
       "2  1.113726       2.041038             0.919988  1.002635  1.502796   \n",
       "3  1.113726       2.041038            -0.554872 -0.997372  1.502796   \n",
       "4  1.113726       2.041038             2.642660 -0.997372  1.502796   \n",
       "\n",
       "   IsWeekend  CompetitionOpenMonths  Promo2OpenMonths  IsPromo2Month  \\\n",
       "0  -0.460344               0.614306         -0.686969      -0.418274   \n",
       "1  -0.460344               0.767705          2.690605       2.390776   \n",
       "2  -0.460344               0.936443          2.046518       2.390776   \n",
       "3  -0.460344               0.430228         -0.686969      -0.418274   \n",
       "4  -0.460344              -0.597541         -0.686969      -0.418274   \n",
       "\n",
       "   Store_Avg_Sales  Store_Median_Sales  Store_Std_Sales  Store_Max_Sales  \\\n",
       "0        -0.912031           -0.875946        -1.347031        -1.099009   \n",
       "1        -0.831141           -0.817777        -0.393441        -0.883690   \n",
       "2        -0.005375           -0.032493         0.536538         0.050540   \n",
       "3         1.114030            1.170027         0.126185         0.372025   \n",
       "4        -0.946421           -0.889205        -0.145339        -0.695239   \n",
       "\n",
       "   Store_Min_Sales  DayOfWeek_1  DayOfWeek_2  DayOfWeek_3  DayOfWeek_4  \\\n",
       "0        -0.281003          0.0          0.0          0.0          0.0   \n",
       "1        -0.571867          0.0          0.0          0.0          0.0   \n",
       "2         0.095873          0.0          0.0          0.0          0.0   \n",
       "3         2.021615          0.0          0.0          0.0          0.0   \n",
       "4        -0.897529          0.0          0.0          0.0          0.0   \n",
       "\n",
       "   DayOfWeek_5  DayOfWeek_6  DayOfWeek_7  DayOfMonth_1  DayOfMonth_2  \\\n",
       "0          1.0          0.0          0.0           0.0           0.0   \n",
       "1          1.0          0.0          0.0           0.0           0.0   \n",
       "2          1.0          0.0          0.0           0.0           0.0   \n",
       "3          1.0          0.0          0.0           0.0           0.0   \n",
       "4          1.0          0.0          0.0           0.0           0.0   \n",
       "\n",
       "   DayOfMonth_3  DayOfMonth_4  DayOfMonth_5  DayOfMonth_6  DayOfMonth_7  \\\n",
       "0           0.0           0.0           0.0           0.0           0.0   \n",
       "1           0.0           0.0           0.0           0.0           0.0   \n",
       "2           0.0           0.0           0.0           0.0           0.0   \n",
       "3           0.0           0.0           0.0           0.0           0.0   \n",
       "4           0.0           0.0           0.0           0.0           0.0   \n",
       "\n",
       "   DayOfMonth_8  DayOfMonth_9  DayOfMonth_10  DayOfMonth_11  DayOfMonth_12  \\\n",
       "0           0.0           0.0            0.0            0.0            0.0   \n",
       "1           0.0           0.0            0.0            0.0            0.0   \n",
       "2           0.0           0.0            0.0            0.0            0.0   \n",
       "3           0.0           0.0            0.0            0.0            0.0   \n",
       "4           0.0           0.0            0.0            0.0            0.0   \n",
       "\n",
       "   DayOfMonth_13  DayOfMonth_14  DayOfMonth_15  DayOfMonth_16  DayOfMonth_17  \\\n",
       "0            0.0            0.0            0.0            0.0            0.0   \n",
       "1            0.0            0.0            0.0            0.0            0.0   \n",
       "2            0.0            0.0            0.0            0.0            0.0   \n",
       "3            0.0            0.0            0.0            0.0            0.0   \n",
       "4            0.0            0.0            0.0            0.0            0.0   \n",
       "\n",
       "   DayOfMonth_18  DayOfMonth_19  DayOfMonth_20  DayOfMonth_21  DayOfMonth_22  \\\n",
       "0            0.0            0.0            0.0            0.0            0.0   \n",
       "1            0.0            0.0            0.0            0.0            0.0   \n",
       "2            0.0            0.0            0.0            0.0            0.0   \n",
       "3            0.0            0.0            0.0            0.0            0.0   \n",
       "4            0.0            0.0            0.0            0.0            0.0   \n",
       "\n",
       "   DayOfMonth_23  DayOfMonth_24  DayOfMonth_25  DayOfMonth_26  DayOfMonth_27  \\\n",
       "0            0.0            0.0            0.0            0.0            0.0   \n",
       "1            0.0            0.0            0.0            0.0            0.0   \n",
       "2            0.0            0.0            0.0            0.0            0.0   \n",
       "3            0.0            0.0            0.0            0.0            0.0   \n",
       "4            0.0            0.0            0.0            0.0            0.0   \n",
       "\n",
       "   DayOfMonth_28  DayOfMonth_29  DayOfMonth_30  DayOfMonth_31  StateHoliday_0  \\\n",
       "0            0.0            0.0            0.0            1.0             1.0   \n",
       "1            0.0            0.0            0.0            1.0             1.0   \n",
       "2            0.0            0.0            0.0            1.0             1.0   \n",
       "3            0.0            0.0            0.0            1.0             1.0   \n",
       "4            0.0            0.0            0.0            1.0             1.0   \n",
       "\n",
       "   StateHoliday_a  StateHoliday_b  StateHoliday_c  StoreType_a  StoreType_b  \\\n",
       "0             0.0             0.0             0.0          0.0          0.0   \n",
       "1             0.0             0.0             0.0          1.0          0.0   \n",
       "2             0.0             0.0             0.0          1.0          0.0   \n",
       "3             0.0             0.0             0.0          0.0          0.0   \n",
       "4             0.0             0.0             0.0          1.0          0.0   \n",
       "\n",
       "   StoreType_c  StoreType_d  Assortment_a  Assortment_b  Assortment_c  \\\n",
       "0          1.0          0.0           1.0           0.0           0.0   \n",
       "1          0.0          0.0           1.0           0.0           0.0   \n",
       "2          0.0          0.0           1.0           0.0           0.0   \n",
       "3          1.0          0.0           0.0           0.0           1.0   \n",
       "4          0.0          0.0           1.0           0.0           0.0   \n",
       "\n",
       "   Month_1  Month_2  Month_3  Month_4  Month_5  Month_6  Month_7  Month_8  \\\n",
       "0      0.0      0.0      0.0      0.0      0.0      0.0      1.0      0.0   \n",
       "1      0.0      0.0      0.0      0.0      0.0      0.0      1.0      0.0   \n",
       "2      0.0      0.0      0.0      0.0      0.0      0.0      1.0      0.0   \n",
       "3      0.0      0.0      0.0      0.0      0.0      0.0      1.0      0.0   \n",
       "4      0.0      0.0      0.0      0.0      0.0      0.0      1.0      0.0   \n",
       "\n",
       "   Month_9  Month_10  Month_11  Month_12  Quarter_1  Quarter_2  Quarter_3  \\\n",
       "0      0.0       0.0       0.0       0.0        0.0        0.0        1.0   \n",
       "1      0.0       0.0       0.0       0.0        0.0        0.0        1.0   \n",
       "2      0.0       0.0       0.0       0.0        0.0        0.0        1.0   \n",
       "3      0.0       0.0       0.0       0.0        0.0        0.0        1.0   \n",
       "4      0.0       0.0       0.0       0.0        0.0        0.0        1.0   \n",
       "\n",
       "   Quarter_4  WeekOfYear_1.0  WeekOfYear_2.0  WeekOfYear_3.0  WeekOfYear_4.0  \\\n",
       "0        0.0             0.0             0.0             0.0             0.0   \n",
       "1        0.0             0.0             0.0             0.0             0.0   \n",
       "2        0.0             0.0             0.0             0.0             0.0   \n",
       "3        0.0             0.0             0.0             0.0             0.0   \n",
       "4        0.0             0.0             0.0             0.0             0.0   \n",
       "\n",
       "   WeekOfYear_5.0  WeekOfYear_6.0  WeekOfYear_7.0  WeekOfYear_8.0  \\\n",
       "0             0.0             0.0             0.0             0.0   \n",
       "1             0.0             0.0             0.0             0.0   \n",
       "2             0.0             0.0             0.0             0.0   \n",
       "3             0.0             0.0             0.0             0.0   \n",
       "4             0.0             0.0             0.0             0.0   \n",
       "\n",
       "   WeekOfYear_9.0  WeekOfYear_10.0  WeekOfYear_11.0  WeekOfYear_12.0  \\\n",
       "0             0.0              0.0              0.0              0.0   \n",
       "1             0.0              0.0              0.0              0.0   \n",
       "2             0.0              0.0              0.0              0.0   \n",
       "3             0.0              0.0              0.0              0.0   \n",
       "4             0.0              0.0              0.0              0.0   \n",
       "\n",
       "   WeekOfYear_13.0  WeekOfYear_14.0  WeekOfYear_15.0  WeekOfYear_16.0  \\\n",
       "0              0.0              0.0              0.0              0.0   \n",
       "1              0.0              0.0              0.0              0.0   \n",
       "2              0.0              0.0              0.0              0.0   \n",
       "3              0.0              0.0              0.0              0.0   \n",
       "4              0.0              0.0              0.0              0.0   \n",
       "\n",
       "   WeekOfYear_17.0  WeekOfYear_18.0  WeekOfYear_19.0  WeekOfYear_20.0  \\\n",
       "0              0.0              0.0              0.0              0.0   \n",
       "1              0.0              0.0              0.0              0.0   \n",
       "2              0.0              0.0              0.0              0.0   \n",
       "3              0.0              0.0              0.0              0.0   \n",
       "4              0.0              0.0              0.0              0.0   \n",
       "\n",
       "   WeekOfYear_21.0  WeekOfYear_22.0  WeekOfYear_23.0  WeekOfYear_24.0  \\\n",
       "0              0.0              0.0              0.0              0.0   \n",
       "1              0.0              0.0              0.0              0.0   \n",
       "2              0.0              0.0              0.0              0.0   \n",
       "3              0.0              0.0              0.0              0.0   \n",
       "4              0.0              0.0              0.0              0.0   \n",
       "\n",
       "   WeekOfYear_25.0  WeekOfYear_26.0  WeekOfYear_27.0  WeekOfYear_28.0  \\\n",
       "0              0.0              0.0              0.0              0.0   \n",
       "1              0.0              0.0              0.0              0.0   \n",
       "2              0.0              0.0              0.0              0.0   \n",
       "3              0.0              0.0              0.0              0.0   \n",
       "4              0.0              0.0              0.0              0.0   \n",
       "\n",
       "   WeekOfYear_29.0  WeekOfYear_30.0  WeekOfYear_31.0  WeekOfYear_32.0  \\\n",
       "0              0.0              0.0              1.0              0.0   \n",
       "1              0.0              0.0              1.0              0.0   \n",
       "2              0.0              0.0              1.0              0.0   \n",
       "3              0.0              0.0              1.0              0.0   \n",
       "4              0.0              0.0              1.0              0.0   \n",
       "\n",
       "   WeekOfYear_33.0  WeekOfYear_34.0  WeekOfYear_35.0  WeekOfYear_36.0  \\\n",
       "0              0.0              0.0              0.0              0.0   \n",
       "1              0.0              0.0              0.0              0.0   \n",
       "2              0.0              0.0              0.0              0.0   \n",
       "3              0.0              0.0              0.0              0.0   \n",
       "4              0.0              0.0              0.0              0.0   \n",
       "\n",
       "   WeekOfYear_37.0  WeekOfYear_38.0  WeekOfYear_39.0  WeekOfYear_40.0  \\\n",
       "0              0.0              0.0              0.0              0.0   \n",
       "1              0.0              0.0              0.0              0.0   \n",
       "2              0.0              0.0              0.0              0.0   \n",
       "3              0.0              0.0              0.0              0.0   \n",
       "4              0.0              0.0              0.0              0.0   \n",
       "\n",
       "   WeekOfYear_41.0  WeekOfYear_42.0  WeekOfYear_43.0  WeekOfYear_44.0  \\\n",
       "0              0.0              0.0              0.0              0.0   \n",
       "1              0.0              0.0              0.0              0.0   \n",
       "2              0.0              0.0              0.0              0.0   \n",
       "3              0.0              0.0              0.0              0.0   \n",
       "4              0.0              0.0              0.0              0.0   \n",
       "\n",
       "   WeekOfYear_45.0  WeekOfYear_46.0  WeekOfYear_47.0  WeekOfYear_48.0  \\\n",
       "0              0.0              0.0              0.0              0.0   \n",
       "1              0.0              0.0              0.0              0.0   \n",
       "2              0.0              0.0              0.0              0.0   \n",
       "3              0.0              0.0              0.0              0.0   \n",
       "4              0.0              0.0              0.0              0.0   \n",
       "\n",
       "   WeekOfYear_49.0  WeekOfYear_50.0  WeekOfYear_51.0  WeekOfYear_52.0  \n",
       "0              0.0              0.0              0.0              0.0  \n",
       "1              0.0              0.0              0.0              0.0  \n",
       "2              0.0              0.0              0.0              0.0  \n",
       "3              0.0              0.0              0.0              0.0  \n",
       "4              0.0              0.0              0.0              0.0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7938c1a0",
   "metadata": {},
   "source": [
    "## PyTorch Tensor Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d6894e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data into a validation and training set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train,  \n",
    "    y_train,  \n",
    "    test_size = 0.2,\n",
    "    random_state = 42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "31ec95ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.tensor(X_train.values, dtype = torch.float32)\n",
    "X_valid_tensor = torch.tensor(X_valid.values, dtype = torch.float32)\n",
    "\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype = torch.float32)\n",
    "y_valid_tensor = torch.tensor(y_valid.values, dtype = torch.float32)\n",
    "\n",
    "X_test_tensor  = torch.tensor(X_test.values, dtype = torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "93dcb239",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([675513, 131]), torch.Size([675513, 1]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tensor.shape, y_train_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aa6d346d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([168879, 131]), torch.Size([168879, 1]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid_tensor.shape, y_valid_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e240f2e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mps'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "eded451e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = X_train_tensor.to(device)\n",
    "y_train_tensor = y_train_tensor.to(device)\n",
    "X_valid_tensor = X_valid_tensor.to(device)\n",
    "y_valid_tensor = y_valid_tensor.to(device)\n",
    "X_test_tensor  = X_test_tensor.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ace8cea",
   "metadata": {},
   "source": [
    "## Creating Neural Network Model, Loss Function, and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1b3a771f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_features = X_train_tensor.shape[1]\n",
    "n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2c07c8d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SalesRegressor(\n",
       "  (linear_layers): Sequential(\n",
       "    (0): Linear(in_features=131, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class SalesRegressor(nn.Module):\n",
    "    def __init__(self, n_features: int):\n",
    "        super().__init__()\n",
    "        self.linear_layers = nn.Sequential(\n",
    "            nn.Linear(in_features = n_features, out_features = 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features = 128, out_features = 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features = 64, out_features = 1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.linear_layers(x)\n",
    "    \n",
    "model = SalesRegressor(n_features = 131).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "19009076",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr = 1e-2,\n",
    "    weight_decay = 1e-5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350c3921",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "167d0f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Train MSE: 7616.8545 | Validation MSE: 7616.0643\n",
      "Epoch 10 | Train MSE: 7587.2280 | Validation MSE: 7577.0744\n",
      "Epoch 20 | Train MSE: 7345.7683 | Validation MSE: 7296.0485\n",
      "Epoch 30 | Train MSE: 6461.5534 | Validation MSE: 6314.6135\n",
      "Epoch 40 | Train MSE: 4263.9512 | Validation MSE: 3963.1566\n",
      "Epoch 50 | Train MSE: 1779.6081 | Validation MSE: 1856.1354\n",
      "Epoch 60 | Train MSE: 2089.4652 | Validation MSE: 1981.9816\n",
      "Epoch 70 | Train MSE: 1624.2133 | Validation MSE: 1648.4933\n",
      "Epoch 80 | Train MSE: 1566.8770 | Validation MSE: 1553.4906\n",
      "Epoch 90 | Train MSE: 1493.4551 | Validation MSE: 1498.0569\n",
      "Epoch 100 | Train MSE: 1453.0570 | Validation MSE: 1454.1063\n",
      "Epoch 110 | Train MSE: 1433.2953 | Validation MSE: 1435.6332\n",
      "Epoch 120 | Train MSE: 1412.4785 | Validation MSE: 1414.9241\n",
      "Epoch 130 | Train MSE: 1398.6353 | Validation MSE: 1400.6743\n",
      "Epoch 140 | Train MSE: 1387.0356 | Validation MSE: 1389.1836\n",
      "Epoch 150 | Train MSE: 1377.4548 | Validation MSE: 1379.4853\n",
      "Epoch 160 | Train MSE: 1369.7249 | Validation MSE: 1371.6448\n",
      "Epoch 170 | Train MSE: 1363.3458 | Validation MSE: 1365.2026\n",
      "Epoch 180 | Train MSE: 1358.0873 | Validation MSE: 1359.8677\n",
      "Epoch 190 | Train MSE: 1353.7429 | Validation MSE: 1355.4658\n",
      "Epoch 200 | Train MSE: 1350.1268 | Validation MSE: 1351.8046\n",
      "Epoch 210 | Train MSE: 1347.1027 | Validation MSE: 1348.7395\n",
      "Epoch 220 | Train MSE: 1344.5524 | Validation MSE: 1346.1560\n",
      "Epoch 230 | Train MSE: 1342.3711 | Validation MSE: 1343.9448\n",
      "Epoch 240 | Train MSE: 1340.4728 | Validation MSE: 1342.0226\n",
      "Epoch 250 | Train MSE: 1338.7915 | Validation MSE: 1340.3219\n",
      "Epoch 260 | Train MSE: 1337.2710 | Validation MSE: 1338.7852\n",
      "Epoch 270 | Train MSE: 1335.8662 | Validation MSE: 1337.3677\n",
      "Epoch 280 | Train MSE: 1334.5416 | Validation MSE: 1336.0310\n",
      "Epoch 290 | Train MSE: 1333.2704 | Validation MSE: 1334.7497\n",
      "Epoch 300 | Train MSE: 1332.0319 | Validation MSE: 1333.5040\n",
      "Epoch 310 | Train MSE: 1330.8100 | Validation MSE: 1332.2765\n",
      "Epoch 320 | Train MSE: 1329.5910 | Validation MSE: 1331.0557\n",
      "Epoch 330 | Train MSE: 1328.3675 | Validation MSE: 1329.8284\n",
      "Epoch 340 | Train MSE: 1327.1285 | Validation MSE: 1328.5859\n",
      "Epoch 350 | Train MSE: 1325.8689 | Validation MSE: 1327.3214\n",
      "Epoch 360 | Train MSE: 1324.5808 | Validation MSE: 1326.0269\n",
      "Epoch 370 | Train MSE: 1323.2541 | Validation MSE: 1324.6929\n",
      "Epoch 380 | Train MSE: 1321.8831 | Validation MSE: 1323.3110\n",
      "Epoch 390 | Train MSE: 1320.4630 | Validation MSE: 1321.8790\n",
      "Epoch 400 | Train MSE: 1318.9859 | Validation MSE: 1320.3897\n",
      "Epoch 410 | Train MSE: 1317.4455 | Validation MSE: 1318.8354\n",
      "Epoch 420 | Train MSE: 1315.8367 | Validation MSE: 1317.2109\n",
      "Epoch 430 | Train MSE: 1314.1505 | Validation MSE: 1315.5117\n",
      "Epoch 440 | Train MSE: 1312.3826 | Validation MSE: 1313.7310\n",
      "Epoch 450 | Train MSE: 1310.5265 | Validation MSE: 1311.8621\n",
      "Epoch 460 | Train MSE: 1308.5790 | Validation MSE: 1309.9000\n",
      "Epoch 470 | Train MSE: 1306.5373 | Validation MSE: 1307.8407\n",
      "Epoch 480 | Train MSE: 1304.3989 | Validation MSE: 1305.6882\n",
      "Epoch 490 | Train MSE: 1302.1568 | Validation MSE: 1303.4359\n"
     ]
    }
   ],
   "source": [
    "epochs = 500\n",
    "torch.manual_seed(42)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad() #Zero grad optimizer\n",
    "    y_pred = model(X_train_tensor) #Forward pass\n",
    "    loss = loss_fn(y_pred, y_train_tensor) #Calculate loss\n",
    "    loss.backward() #Backpropagation\n",
    "    optimizer.step() #Gradient Descent\n",
    "\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        valid_pred = model(X_valid_tensor)\n",
    "        valid_loss = loss_fn(valid_pred, y_valid_tensor)\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        train_rsme = loss.item() ** 0.5\n",
    "        valid_rsme = valid_loss.item() ** 0.5\n",
    "        print(f\"Epoch {epoch} | Train MSE: {train_rsme:.4f} | Validation MSE: {valid_rsme:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ddaf339b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.inference_mode():\n",
    "    test_preds = model(X_test_tensor.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ef792aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = test_preds.cpu().numpy().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "88be4c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_csv('../Data/test.csv')\n",
    "submission = pd.DataFrame({\n",
    "    \"Id\": X_test['Id'],\n",
    "    \"Open\": X_test['Open'],\n",
    "    \"Sales\": test_preds  \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5c143f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.loc[submission['Open'] == 0, 'Sales'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4542b0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.drop(columns = ['Open'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5a0d8571",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('../Data/nn.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6009f4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
